run_id = "consilience-match-llama2-20m-fineweb"
run_state = "WaitingForMembers"
[config]
warmup_time = 30
cooldown_time = 5
rounds_per_epoch = 20
max_round_train_time = 3000
round_witness_time = 2
round_apply_time = 4
min_clients = 2
init_min_clients = 2
global_batch_size_start = 4
global_batch_size_end = 4
global_batch_size_warmup_tokens = 0
verification_percent = 0
witness_nodes = 1
total_steps = 25000

[model.LLM]
architecture = "HfLlama"
data_type = "Pretraining"
max_seq_len = 512
[model.LLM.data_location]
Server = "127.0.0.1:20001"
[model.LLM.checkpoint.Hub]
repo_id = "emozilla/llama2-20m-init"
[model.LLM.lr_schedule.Cosine]
base_lr = 4.0e-4
warmup_steps = 20
warmup_init_lr = 0.0
total_steps = 2000
final_lr = 4.0e-5
[model.LLM.optimizer.Distro]
compression_decay = 0.999
compression_chunk = 16
compression_topk = 4
quantize_1bit = false
